{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b5cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    " import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbdd27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358942db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientists\n",
      "and\n",
      "Dr.\n",
      "have\n",
      "discovered\n",
      "a\n",
      "new\n",
      "species\n",
      "of\n",
      "bird\n",
      "in\n",
      "the\n",
      "Amazon\n",
      "rainforest\n",
      ".\n",
      "The\n",
      "bird\n",
      "has\n",
      "bright\n",
      "blue\n",
      "feathers\n",
      "and\n",
      "a\n",
      "distinctive\n",
      "call\n",
      "that\n",
      "has\n",
      "not\n",
      "been\n",
      "heard\n",
      "before\n",
      ".\n",
      "The\n",
      "researchers\n",
      "are\n",
      "excited\n",
      "to\n",
      "study\n",
      "the\n",
      "behavior\n",
      "and\n",
      "ecology\n",
      "of\n",
      "this\n",
      "new\n",
      "species\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"Scientists and Dr. have discovered a new species of bird in the Amazon rainforest. The bird has bright blue feathers and a distinctive call that has not been heard before. The researchers are excited to study the behavior and ecology of this new species.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72aae630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f24c6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39db6c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41f190e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[1]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47bdc87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony gave two $ to Peter."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Tony gave two $ to Peter.\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4287b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0 = doc[0]\n",
    "token0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "687d183f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da465a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f8b7a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "gave ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "two ==> index:  2 is_alpha: True is_punct: False like_num: True is_currency: False\n",
      "$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\n",
      "to ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "Peter ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      ". ==> index:  6 is_alpha: False is_punct: True like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \"==>\", \"index: \", token.i,\n",
    "         \"is_alpha:\", token.is_alpha,\n",
    "         \"is_punct:\", token.is_punct,\n",
    "         \"like_num:\", token.like_num,\n",
    "         \"is_currency:\", token.is_currency\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2e09a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirth day   \\temail\\n',\n",
       " '-----\\t------------\\t------\\n',\n",
       " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
       " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
       " 'Joe      1 May, 1997    joe@root.com']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"students.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8310a995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "251fba23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "emails = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "769fe884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "यो False False\n",
      "जानकारी False False\n",
      "दानियलको False False\n",
      "भविष्यवाणी False False\n",
      "किताब False False\n",
      ", False False\n",
      "पृष्ठ False False\n",
      "५७ False True\n",
      ", False False\n",
      "अनुच्छेद False False\n",
      "२४ False True\n",
      "अनि False False\n",
      "पृष्ठ False False\n",
      "५६ False True\n",
      "र False False\n",
      "१३९ False True\n",
      "को False False\n",
      "तालिकामा False False\n",
      "छलफल False False\n",
      "गरिएको False False\n",
      "जानकारीभन्दा False False\n",
      "नयाँ False False\n",
      "जानकारी False False\n",
      "हो False False\n",
      "। False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"ne\")\n",
    "doc = nlp(\"यो जानकारी दानियलको भविष्यवाणी किताब, पृष्ठ ५७, अनुच्छेद २४ अनि पृष्ठ ५६ र १३९ को तालिकामा छलफल गरिएको जानकारीभन्दा नयाँ जानकारी हो।\") \n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.is_currency, token.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a92ac00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customize tokenizer\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dc45465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case(\"gimme\",[\n",
    "    {ORTH: \"gim\"},\n",
    "    {ORTH: \"me\"}\n",
    "])  \n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "488701d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x27cbdefec00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe6cf5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fc91814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange loves momo of Nepal.\n",
      "Hulk loves pizza of Kathmandu.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves momo of Nepal. Hulk loves pizza of Kathmandu.\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10cfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
